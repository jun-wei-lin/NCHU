{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOQ/dUFcRu0AN91yQuvm1k2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jun-wei-lin/NCHU/blob/main/AIoT-DA/Transfer%20Learning%20and%20Hugging%20Face/HW6_1_Transfer_learning_on_pretrained_VGG_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "步驟 1：克隆資料集"
      ],
      "metadata": {
        "id": "HQQEzkjmqfXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 在 Colab 中執行以下程式碼來克隆資料庫\n",
        "!git clone https://github.com/chandrikadeb7/Face-Mask-Detection.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYTFE7GaqhNH",
        "outputId": "60b42cec-1293-450b-9e01-c59e0827627e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Face-Mask-Detection' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "步驟 2：設置資料路徑與載入資料"
      ],
      "metadata": {
        "id": "FIGREWfLqjT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 資料路徑\n",
        "dataset_dir = 'Face-Mask-Detection/dataset'\n",
        "\n",
        "# 數據生成器\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(128, 128),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6NO4JSTqiJi",
        "outputId": "f34f49ba-0ebc-4245-a8fa-d1fe1a42107b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3274 images belonging to 2 classes.\n",
            "Found 818 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "步驟 3：建構 VGG16 遷移學習模型"
      ],
      "metadata": {
        "id": "F_oy1fKlqmJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 建構 VGG16 模型\n",
        "def build_vgg16_model(num_classes=2):\n",
        "    base_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "    base_model.trainable = False\n",
        "\n",
        "    model = models.Sequential([\n",
        "        base_model,\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "model = build_vgg16_model(num_classes=2)"
      ],
      "metadata": {
        "id": "cA5zftB1qoQT"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "步驟 4：訓練模型"
      ],
      "metadata": {
        "id": "ZuHDuexJqrZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練模型\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEV28yd-qrDl",
        "outputId": "7c5b8f3b-465d-4f79-ef0e-261eb1b45bae"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 69ms/step - accuracy: 0.8609 - loss: 0.3816 - val_accuracy: 0.9841 - val_loss: 0.0493\n",
            "Epoch 2/10\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 56ms/step - accuracy: 0.9760 - loss: 0.0697 - val_accuracy: 0.9756 - val_loss: 0.0725\n",
            "Epoch 3/10\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.9833 - loss: 0.0479 - val_accuracy: 0.9841 - val_loss: 0.0415\n",
            "Epoch 4/10\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 54ms/step - accuracy: 0.9837 - loss: 0.0415 - val_accuracy: 0.9817 - val_loss: 0.0569\n",
            "Epoch 5/10\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.9874 - loss: 0.0339 - val_accuracy: 0.9866 - val_loss: 0.0414\n",
            "Epoch 6/10\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.9770 - loss: 0.0517 - val_accuracy: 0.9670 - val_loss: 0.0981\n",
            "Epoch 7/10\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.9896 - loss: 0.0252 - val_accuracy: 0.9841 - val_loss: 0.0507\n",
            "Epoch 8/10\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 56ms/step - accuracy: 0.9906 - loss: 0.0246 - val_accuracy: 0.9853 - val_loss: 0.0537\n",
            "Epoch 9/10\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 56ms/step - accuracy: 0.9937 - loss: 0.0151 - val_accuracy: 0.9841 - val_loss: 0.0708\n",
            "Epoch 10/10\n",
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.9961 - loss: 0.0143 - val_accuracy: 0.9817 - val_loss: 0.0647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "步驟 5：測試模型"
      ],
      "metadata": {
        "id": "mgL8qM3Tqtb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 評估模型\n",
        "test_loss, test_accuracy = model.evaluate(val_generator)\n",
        "print(f\"Validation Loss: {test_loss:.4f}, Validation Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9yAGqXDqvut",
        "outputId": "15483a0e-4290-41ee-f826-89cbec321290"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9848 - loss: 0.0482\n",
            "Validation Loss: 0.0647, Validation Accuracy: 0.9817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "步驟 6：從圖片網址進行分類"
      ],
      "metadata": {
        "id": "QC9UuN53qxdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "# 處理圖片的函數\n",
        "def preprocess_image_from_url(image_url, target_size=(128, 128)):\n",
        "    response = requests.get(image_url)  # 下載圖片\n",
        "    image = Image.open(BytesIO(response.content))  # 開啟圖片\n",
        "    image = image.convert('RGB')  # 確保是 RGB 模式\n",
        "    image = image.resize(target_size)  # 調整大小\n",
        "    img_array = img_to_array(image) / 255.0  # 正規化\n",
        "    return np.expand_dims(img_array, axis=0)  # 增加批次維度\n",
        "\n",
        "# 測試圖片分類的函數\n",
        "def test_image(image_url, model, class_indices):\n",
        "    # 將 class_indices 的鍵值對轉換成索引到類別名稱的映射\n",
        "    idx_to_class = {v: k for k, v in class_indices.items()}\n",
        "\n",
        "    # 預處理輸入圖片\n",
        "    img_array = preprocess_image_from_url(image_url)\n",
        "\n",
        "    # 預測\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class_idx = np.argmax(predictions)  # 找到預測的索引\n",
        "    predicted_class = idx_to_class[predicted_class_idx]  # 索引映射到類別名稱\n",
        "\n",
        "    print(f\"該圖片分類結果為：{predicted_class}\")\n",
        "\n",
        "# 使用範例\n",
        "image_url = input(\"輸入圖片網址: \")\n",
        "test_image(image_url, model, train_generator.class_indices)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CypENyCOqyNF",
        "outputId": "3ebb7203-6414-4089-9f4e-e6a45d123ec3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "輸入圖片網址: https://github.com/chandrikadeb7/Face-Mask-Detection/blob/master/dataset/without_mask/0_0_aidai_0084.jpg?raw=true\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "該圖片分類結果為：without_mask\n"
          ]
        }
      ]
    }
  ]
}