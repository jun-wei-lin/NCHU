# HW4-1: Naive DQN for Static Mode ğŸ§ ğŸ¯

æœ¬å°ˆæ¡ˆå¯¦ä½œ Naive DQN å¼·åŒ–å­¸ç¿’æ¼”ç®—æ³•ï¼Œä¸¦æ‡‰ç”¨æ–¼éœæ…‹æ ¼å­ç’°å¢ƒï¼ˆStatic GridWorldï¼‰ä¸­ï¼Œå®ŒæˆåŸºæœ¬è¨“ç·´èˆ‡æ¸¬è©¦æµç¨‹ï¼Œé©—è­‰ Q-Learning çš„æ•ˆæœã€‚

---

## ğŸ“Œ ä»»å‹™ç›®æ¨™

> âœ… å¯¦ä½œåŸºæœ¬ DQN æ¼”ç®—æ³•  
> âœ… æ­é… Experience Replay å¢å¼·ç©©å®šæ€§  
> âœ… æ‡‰ç”¨æ–¼ `static` æ¨¡å¼ï¼Œé©—è­‰ç­–ç•¥æ˜¯å¦å­¸ç¿’æˆåŠŸ  

---

## ğŸ§  DQN æ¶æ§‹ç°¡è¿°

- ä½¿ç”¨ **MLPï¼ˆMulti-Layer Perceptronï¼‰** ç•¶ä½œ Q-Network
- æ¡ç”¨ **MSE Loss + Adam Optimizer**
- ä½¿ç”¨ **Îµ-greedy** ç­–ç•¥é€²è¡Œæ¢ç´¢èˆ‡åˆ©ç”¨
- ç¶“é©—é‡æ”¾ï¼ˆExperience Replay Bufferï¼‰é¿å…æ¨£æœ¬ç›¸é—œæ€§

---

## ğŸ§ª åŸ·è¡Œçµæœ

å…±è¨“ç·´ 50 å›åˆï¼Œæ¸¬è©¦ 5 æ¬¡çš†å›å ±ç‚º **+1.0**ï¼Œè¡¨ç¤º agent èƒ½æˆåŠŸæ‰¾åˆ°æ­£ç¢ºç­–ç•¥ã€‚

### è¨“ç·´ç´€éŒ„ï¼ˆç¯€éŒ„ï¼‰ï¼š
![image](https://github.com/user-attachments/assets/94c2e5e8-132d-49a8-bb45-26b85c01f8c7)
![image](https://github.com/user-attachments/assets/885ec943-e188-4dbe-8cbc-2053331aa55b)

---


## ğŸ“‚ æª”æ¡ˆèªªæ˜

| æª”æ¡ˆåç¨± | èªªæ˜ |
|----------|------|
| `hw4_1_naive_dqn_static.py` | ä¸»ç¨‹å¼ï¼ŒåŒ…å« Q-networkã€ReplayBufferã€è¨“ç·´èˆ‡æ¸¬è©¦é‚è¼¯ |
| `requirements.txt` | å¥—ä»¶å®‰è£æ¸…å–®ï¼ˆå»ºè­°åŒ…å« `gym`, `numpy`, `torch`ï¼‰ |

---

## ğŸš€ åŸ·è¡Œæ–¹å¼

### å®‰è£å¥—ä»¶
```bash
pip install gym numpy torch
```

### åŸ·è¡Œä¸»ç¨‹å¼
python hw4_1_naive_dqn_static.py

